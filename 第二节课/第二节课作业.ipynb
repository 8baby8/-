{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 普通作业(前提：已克隆虚拟环境)\n",
    "## 1.生成300字小故事"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境配置\n",
    "# 升级pip\n",
    "!python -m pip install --upgrade pip\n",
    "%pip install modelscope==1.9.5\n",
    "%pip install transformers==4.35.2\n",
    "%pip install streamlit==1.24.0\n",
    "%pip install sentencepiece==0.1.99\n",
    "%pip install accelerate==0.24.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下方cell直接对话（很方便，一次一次被震撼）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "model_name_or_path = \"/root/model/Shanghai_AI_Laboratory/internlm-chat-7b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path, trust_remote_code=True, torch_dtype=torch.bfloat16, device_map='auto')\n",
    "model = model.eval()\n",
    "\n",
    "system_prompt = \"\"\"You are an AI assistant whose name is InternLM (书生·浦语).\n",
    "- InternLM (书生·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be helpful, honest, and harmless.\n",
    "- InternLM (书生·浦语) can understand and communicate fluently in the language chosen by the user such as English and 中文.\n",
    "\"\"\"\n",
    "\n",
    "messages = [(system_prompt, '')]\n",
    "\n",
    "print(\"=============Welcome to InternLM chatbot, type 'exit' to exit.=============\")\n",
    "\n",
    "# while True:\n",
    "# input_text = input(\"User  >>> \")\n",
    "# input_text = input_text.replace(' ', '')\n",
    "input_text = \"请帮我生成一个300字左右的小故事\"\n",
    "# if input_text == \"exit\":\n",
    "#     break\n",
    "response, history = model.chat(tokenizer, input_text, history=messages)\n",
    "messages.append((input_text, response))\n",
    "print(f\"robot >>> {response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](assets/故事.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 下载cofig.json作业\n",
    "huggingface 对应位置图片\n",
    "![img](assets/huggingface20B.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意网络\n",
    "# 第一种办法\n",
    "import os \n",
    "from huggingface_hub import hf_hub_download  # Load model directly \n",
    "\n",
    "hf_hub_download(repo_id=\"internlm/internlm-20b\", filename=\"config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络不适，可用第二种办法\n",
    "import torch\n",
    "from modelscope import snapshot_download, AutoModel, AutoTokenizer\n",
    "import os\n",
    "model_dir = snapshot_download('Shanghai_AI_Laboratory/internlm-chat-7b', cache_dir='config.json', revision='master')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下载成功图片\n",
    "![img](assets/下载成功.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xtuner0.1.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
